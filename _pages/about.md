---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html


---


Hello, I am Zixuan, a Ph.D. student in Transportation at the [Cho Chun Shik Graduate School of Mobility](https://mobility.kaist.ac.kr/), Korea Advanced Institute of Science and Technology (KAIST). I work in the [üöó HumanFACTS Lab](https://human-facts.kaist.ac.kr/) under the supervision of [Dr. Tiantian(Nicole) Chen](https://sites.google.com/view/chentiantian/home), where we are dedicated to advancing transportation safety through human-centered research and innovation.

My research interest lies in the intersection of <span style="color: #FF8C00;font-weight: 600;">Generative AI</span>, <span style="color: #FF8C00;font-weight: 600;">Human-Machine Interaction (HMI)</span>, and <span style="color: #FF8C00;font-weight: 600;">Autonomous Vehicles (AVs)</span>. I focus on leveraging advanced AI, particularly Large Language Models (LLMs), to create safer, more intuitive, and personalized interactions within intelligent transportation systems. This includes exploring human factors, communication methods, and interface design for AVs. 

Additionally, my work addresses critical safety and societal considerations essential for the responsible deployment of intelligent vehicles, specifically examining <span style="color: #FF8C00;font-weight: 600;">AI trustworthiness</span>, <span style="color: #FF8C00;font-weight: 600;">cybersecurity</span> and <span style="color: #FF8C00;font-weight: 600;"> ethical</span> challenges.

## Research Vision

During my PhD stage, I seek to answer several questions about our future with intelligent systems, including but not limited to:

-  ü§ñ **LLMs for AV Interaction**: How can LLMs enhance human-machine interaction in autonomous vehicles (applications, function, reliance)?

- üîç **AI Evaluation & Validation**: How can we effectively evaluate AI for AV HMI to ensure reliability, robustness, and alignment with human values/safety?

- üß† **Human Behavior Modeling**: How can computational models accurately capture and predict human behavior/intentions in transportation?


---

<div style="padding: 15px 0;">
  üî¨ü§ù<strong>I am always excited to learn from and collaborate with others interested in these areas. Currently, my primary focus is on applying LLMs to solve human-machine interaction challenges (centering on drivers, passengers, and pedestrians) for AVs.</strong>
</div>

<div style="padding: 5px 0;">
  <strong>Feel free to reach out via email <a href="mailto:zixuan.xu@kaist.ac.kr">zixuan.xu@kaist.ac.kr</a> ‚Äî I look forward to connecting!</strong>
</div>
---

## Latest News

{% include news-feed.html %}
[View All News](/news/)

## Recent Publications

{% include featured-publications.html %}
[View All Publications](/publications/)

## Education

- Ph.D., Transportation, 
  Korea Advanced Institute of Science and Technology (KAIST), 2023-present <br>
  *Certified with PhD special scholarship*

- M.S., Data-Driven Modeling, Department of Physics and the Department of Mathematics,
  The Hong Kong University of Science and Technology (HKUST), 2022-2023 <br>
  *Certified with Entry Scholarship*


- B.S., Traffic Engineering,
  Tongji University, 2018-2022


üöÄ LLMs for Reliable Human-Machine Interaction in AVs

Hello everyone! I‚Äôm excited to share two fresh‚Äëonline studies that delve deeper into how large language models (LLMs) can drive safer, more ethical, and more personalized interactions in autonomous vehicles (AVs).

Paper 1: Decoding LLM-Driven Decisions in AV Ethical Dilemmas
‚ÄúBoth academia and industry have harnessed LLMs in autonomous driving‚Äîfor scenario understanding, behavior prediction, and end-to-end control. But can we really trust LLMs for AVs? How would an LLM-based AV react in ethical dilemma scenarios‚Äîe.g., a sudden brake failure? Could LLMs provide moral decision-making solutions?‚Äù

Our Approach: We propose a framework to evaluate and model LLMs(by 2024-07 version)‚Äô ethical values. We used a stated preference experiment with 10,000+ dilemma scenarios and 5 key factors (e.g., number of lives at risk).

Methods: By applying a binary logit model and decision tree analysis, we discovered which factors significantly influence LLMs‚Äô decisions and shed light on their embedded ethical preferences.

Key Takeaway: LLMs often favor saving pedestrians over passengers, aligning with certain human ethics yet also revealing unique biases. This work offer a novel framework of intepreting LLM's choice on ethical dillma in the context of AVs, discusiing LLm's bias and divergence from human value. Through this work, we hope to provide critical insights for responsible AI development in AVs.

Paper 2: Personalizing Driver Assistance With LLMs
Challenge: Traditional driver assistance systems use fixed rules or limited models, offering minimal personalization and inconsistent warnings.

Our Solution: We developed an LLM-based Personalized Driver Agent (LLM-PDA) that adapts safety warnings (visual, voice, tactile) to each driver‚Äôs needs and road conditions in real time.

Outcome: This agent personalizes alerts for diverse driver profiles (e.g., older drivers, foreign drivers), improving usability, safety, and overall human-vehicle interaction.

I‚Äôd like to thank my brilliant coauthors for their collaboration and insights. If these studies pique your interest‚Äîwhether you work in AVs, AI, automotive design, or beyond‚ÄîI‚Äôd love to explore potential partnerships and learn from your perspectives.

Check out my new personal website for more details and future updates: [https://zixuan-xu72.github.io/].
Let‚Äôs connect and shape the future of AI-powered mobility together! ü§ù

#AIethics #AutonomousVehicles #HumanMachineInteraction #LLM #TrafficSafety






