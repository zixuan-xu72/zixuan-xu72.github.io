---
title: "A LLM-based Multimodal Warning System for Driver Assistance"
collection: talks
type: "Conference presentation"
permalink: /talks/2024-09-24-llm-multimodal-warning
venue: "The 2nd Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD), co-located with IEEE ITSC 2024"
date: 2024-09-24
location: "Edmonton, Canada"
---

<img src="/images/talks/itsc-2024-presentation.jpg" alt="Presenting at ITSC 2024" style="width: 100%; margin-bottom: 20px;">

I presented our research on a multimodal warning system for driver assistance powered by Large Language Models at the 2nd Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD), which was co-located with IEEE ITSC 2024 in Edmonton, Canada.

## Talk Abstract

In this presentation, I introduced our novel approach to driver assistance systems using Large Language Models. The talk covered:

1. The architecture of our LLM-based multimodal warning system
2. Integration of visual, auditory, and haptic feedback channels
3. Contextualization of warnings based on driving scenarios
4. Preliminary results showing improvements in driver response time
5. Future directions for personalized driver assistance

## Key Takeaways

- LLMs offer new possibilities for contextual understanding in driver assistance systems
- Multimodal warnings can be more effective than single-channel approaches
- Personalization remains a key challenge for next-generation driver assistance

[Download slides (PDF)](/files/talks/itsc-2024-llm-warning-slides.pdf)